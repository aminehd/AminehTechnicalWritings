{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminehd/AminehTechnicalWritings/blob/main/notebookes/NeuralNetWriting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural network as a generalization of linear regression\n",
        "A linear regression is a linear transformation from multi dimensional input x to one dimensional output y. A classifier neural network as a generalization of linear regression, is also a function that computes an output $y \\in \\mathbb{R}$ from a given input multidimensional $x \\in \\mathbb{R}^{n^{[0]}}$\n",
        "\n",
        "$$\n",
        "y = nn(x), x \\in \\mathbb{R}^{n_0}, y \\in \\mathbb{R}\n",
        "$$\n",
        "\n",
        "We expect output of a classifier (nn) to be between 0 and 1: y should be closer to 1 when x is in the class and closer to 0 when x is not in the class.\n",
        "\n",
        "The goal is to find or train such functions that are more flexible than just a linear transformation. There are infinitely many way to find a function `nn` that satisfies this.  There are ways, however,  to limit our options. For example we can still use some linear transformation with unknown parameters and a fixed non-linear function. For now let’s assume we only need a linear transformation.\n",
        "\n",
        "You can also view a neural net as a function that transforms  $n^{[0]}$ dimensional vector $x$  to a 1 dimensional vector y. If this was a linear transformations, then a matrix of size $(n^{[0]}, 1)$  would do this perfectly, i.e, there exist a matrix $W \\in \\mathbb{R}^{n^{[0]} \\times 1}$\n",
        "\n",
        "$$\n",
        "y = W . x\n",
        "$$\n",
        "\n",
        "####keyword: linear regression, linear transformation\n"
      ],
      "metadata": {
        "id": "rlK-HZjvTiFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How does it deal with non-linearity?\n",
        "\n",
        "\n",
        "A neural net can be as simple as $y = W.x$ When a linear relationship exist from input to output, where W is a linear transformation from  $\\mathbb{R}^{n^{[0]}}$ dimensional vector to $\\mathbb{R}$. If such linearity doesn’t exist, all we need to do is to apply a non-linear function $g$ on top of it\n",
        "\n",
        "$$\n",
        "y = g(W * x)\n",
        "$$\n",
        "\n",
        "In theory, any function can be **represented** as such a non-linear function on top of a linear  transformation. In fact all you need to do is to use any matrix that reshapes input dimension to the output dimension, and then use a nonlinear function that makes all values match for each data point.\n",
        "\n",
        "####keywords: non-linear, represent\n"
      ],
      "metadata": {
        "id": "gMLyFOa7UEvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transforming input to ouput through n layers: feed forward"
      ],
      "metadata": {
        "id": "98LKdweiUUfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###What does it mean to train a neural net? how we do it."
      ],
      "metadata": {
        "id": "eUh3ZdMsUuSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to improve the initial parameters: feed backward"
      ],
      "metadata": {
        "id": "ALKDm-q4Ux1m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chain rule and feed backward. The little nudges goes from right to left"
      ],
      "metadata": {
        "id": "0Cv5JcriVUZI"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}